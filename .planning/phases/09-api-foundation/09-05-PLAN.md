---
phase: 09-api-foundation
plan: 05
type: execute
wave: 3
depends_on: ["09-04"]
files_modified:
  - src/api/services/__init__.py
  - src/api/services/forecast_service.py
  - tests/test_forecast_persistence.py
  - tests/test_concurrent_db.py
autonomous: true

must_haves:
  truths:
    - "ForecastService wraps EnsemblePredictor.predict() and persists the result to PostgreSQL"
    - "A persisted forecast is retrievable via both direct SQL query and GET /api/v1/forecasts/{id}"
    - "Three concurrent Python processes can read/write PostgreSQL without errors or data corruption"
    - "ForecastService maps ForecastOutput + EnsemblePrediction to the Prediction ORM model correctly"
  artifacts:
    - path: "src/api/services/forecast_service.py"
      provides: "ForecastService that calls predict() and persists to PostgreSQL"
      contains: "class ForecastService"
    - path: "tests/test_forecast_persistence.py"
      provides: "Test that predict -> persist -> retrieve round-trips correctly"
      contains: "test_forecast_persist"
    - path: "tests/test_concurrent_db.py"
      provides: "Concurrent database access test with 3 processes"
      contains: "test_concurrent"
  key_links:
    - from: "src/api/services/forecast_service.py"
      to: "src/forecasting/ensemble_predictor.py"
      via: "Calls EnsemblePredictor.predict() then persists result"
      pattern: "EnsemblePredictor|predict"
    - from: "src/api/services/forecast_service.py"
      to: "src/db/models.py"
      via: "Maps ForecastOutput to Prediction ORM model"
      pattern: "Prediction\\("
    - from: "src/api/services/forecast_service.py"
      to: "src/api/schemas/forecast.py"
      via: "Returns ForecastResponse DTO from persisted data"
      pattern: "ForecastResponse"
---

<objective>
Wire the EnsemblePredictor to PostgreSQL persistence and verify concurrent multi-process database access — closing the last two success criteria for Phase 9.

Purpose: Success criterion 4 requires that `EnsemblePredictor.predict()` persists forecasts to PostgreSQL and they're retrievable via both SQL and API. Success criterion 5 requires that three separate processes can read/write concurrently. This plan creates the ForecastService (the glue between prediction and persistence) and verifies the concurrent access pattern that Phases 10 and 13 depend on (FastAPI + ingest daemon + prediction pipeline).

Output: ForecastService class that the daily pipeline (Phase 10) will use. Passing tests for persistence round-trip and concurrent database access.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/phases/09-api-foundation/09-CONTEXT.md
@.planning/phases/09-api-foundation/09-RESEARCH.md

# EnsemblePredictor output types:
@src/forecasting/ensemble_predictor.py
@src/forecasting/models.py

# Database layer from Plan 01:
@src/db/models.py
@src/db/postgres.py

# API schemas from Plan 02:
@src/api/schemas/forecast.py

# API routes from Plan 04 (for integration test):
@src/api/routes/v1/forecasts.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: ForecastService — predict, persist, retrieve</name>
  <files>
    src/api/services/__init__.py
    src/api/services/forecast_service.py
  </files>
  <action>
    1. Create src/api/services/__init__.py (empty).

    2. Create src/api/services/forecast_service.py:

       class ForecastService:
           """Bridges EnsemblePredictor with PostgreSQL persistence.

           The predictor is kept pure — it knows nothing about databases.
           ForecastService calls predict(), maps the output to ORM models,
           persists to PostgreSQL, and returns API-ready DTOs.
           """

           def __init__(self, session: AsyncSession):
               self.session = session

           async def persist_forecast(
               self,
               forecast_output: ForecastOutput,
               ensemble_prediction: EnsemblePrediction,
               country_iso: Optional[str] = None,
           ) -> Prediction:
               """Map ForecastOutput + EnsemblePrediction to Prediction ORM model and persist.

               Field mapping (see 09-RESEARCH.md "EnsemblePredictor Integration Point"):
               - question: forecast_output.question
               - prediction: forecast_output.prediction
               - probability: forecast_output.probability (the calibrated ensemble probability)
               - confidence: forecast_output.confidence
               - horizon_days: forecast_output.horizon_days (default 30 if not present)
               - category: ensemble_prediction.category or "general"
               - reasoning_summary: forecast_output.reasoning_summary or first 500 chars of prediction
               - evidence_count: len(evidence sources across all scenarios)
               - scenarios_json: serialize scenarios to list[dict] via ScenarioDTO mapping
               - ensemble_info_json: {llm_probability, tkg_probability, weights, temperature}
               - calibration_json: {category, temperature, historical_accuracy, brier_score, sample_size}
               - entities: extract unique entity names from scenarios
               - country_iso: from parameter
               - created_at: now(UTC)
               - expires_at: now(UTC) + timedelta(days=horizon_days)

               Persist via session.add() + session.flush() to get the ID back.
               Return the Prediction ORM object.
               """

           async def get_forecast_by_id(self, forecast_id: str) -> Optional[ForecastResponse]:
               """Retrieve a forecast from PostgreSQL and return as ForecastResponse DTO.

               Query Prediction table by id.
               Reconstruct ForecastResponse from ORM fields:
               - Deserialize scenarios_json back to list[ScenarioDTO]
               - Deserialize ensemble_info_json back to EnsembleInfoDTO
               - Deserialize calibration_json back to CalibrationDTO
               Return None if not found.
               """

           async def get_forecasts_by_country(
               self, country_iso: str, cursor: Optional[str] = None, limit: int = 20
           ) -> PaginatedResponse[ForecastResponse]:
               """Retrieve forecasts for a country with cursor pagination.

               Query Prediction table filtered by country_iso, ordered by created_at DESC.
               Decode cursor if provided (contains id + timestamp for keyset pagination).
               Apply limit+1 pattern to determine has_more.
               Return PaginatedResponse with next_cursor if more results exist.
               """

           @staticmethod
           def prediction_to_dto(prediction: Prediction) -> ForecastResponse:
               """Convert Prediction ORM model to ForecastResponse DTO.

               This is the single source of truth for ORM->DTO mapping.
               """

       Note on ForecastOutput mapping: The existing ForecastOutput model (src/forecasting/models.py) has fields like question, prediction, probability, confidence, scenario_tree. The scenario_tree.scenarios are Scenario objects (not ScenarioDTO). The mapping must convert Scenario -> ScenarioDTO:
       - Scenario.scenario_id -> ScenarioDTO.scenario_id
       - Scenario.description -> ScenarioDTO.description
       - Scenario.probability -> ScenarioDTO.probability
       - Scenario.answers_affirmative -> ScenarioDTO.answers_affirmative
       - Scenario.entities -> [e.name for e in Scenario.entities] (Entity objects to strings)
       - Scenario.timeline -> [te.description for te in Scenario.timeline] (TimelineEvent to strings)
       - Scenario.reasoning_path -> EvidenceDTO list mapping
       - Scenario.child_ids -> resolve from scenario tree for child_scenarios

       If the mapping is complex, create a private _map_scenario(scenario: Scenario) -> ScenarioDTO helper.
  </action>
  <verify>
    - `uv run python -c "from src.api.services.forecast_service import ForecastService; print('Import OK')"` succeeds
    - `uv run python -c "
import inspect
from src.api.services.forecast_service import ForecastService
methods = [m for m in dir(ForecastService) if not m.startswith('_')]
print(f'Public methods: {methods}')
assert 'persist_forecast' in methods
assert 'get_forecast_by_id' in methods
assert 'get_forecasts_by_country' in methods
assert 'prediction_to_dto' in methods
print('All methods present')
"` succeeds
  </verify>
  <done>ForecastService class exists with persist_forecast, get_forecast_by_id, get_forecasts_by_country, and prediction_to_dto methods. Maps between EnsemblePredictor output types, Prediction ORM model, and ForecastResponse DTO.</done>
</task>

<task type="auto">
  <name>Task 2: Persistence round-trip test + concurrent database access test</name>
  <files>
    tests/test_forecast_persistence.py
    tests/test_concurrent_db.py
  </files>
  <action>
    1. Create tests/test_forecast_persistence.py:
       - Use pytest-asyncio for async tests
       - Test: create a mock ForecastOutput + EnsemblePrediction (use the existing dataclass constructors with minimal valid data), persist via ForecastService, then:
         a. Retrieve by ID via ForecastService.get_forecast_by_id -> verify all fields match
         b. Retrieve by country via ForecastService.get_forecasts_by_country -> verify it appears in list
         c. Verify the Prediction row exists in PostgreSQL via direct SQL query
       - Test: persist_forecast with missing optional fields (no country_iso, no TKG prediction) succeeds
       - Test: prediction_to_dto correctly reconstructs nested ScenarioDTO from scenarios_json

       IMPORTANT: These tests require a running PostgreSQL. Use the docker-compose postgres service. The test should:
       a. Create a test-specific database or use a transaction that rolls back
       b. Recommended: use a fixture that creates an async session with a savepoint, rolls back after each test

       If creating these tests is too complex due to the EnsemblePredictor's dependencies (it needs Gemini, TKG model, etc.), create mock/synthetic ForecastOutput and EnsemblePrediction objects directly using the dataclass constructors with hardcoded data. DO NOT call the real EnsemblePredictor.predict().

    2. Create tests/test_concurrent_db.py:
       - Test that 3 concurrent async tasks (simulating 3 separate processes) can read/write PostgreSQL without errors:
         a. Task 1 (simulates FastAPI): writes a Prediction row, reads it back
         b. Task 2 (simulates ingest daemon): writes an IngestRun row, reads it back
         c. Task 3 (simulates prediction pipeline): writes a Prediction row, reads it back
       - Run all 3 concurrently via asyncio.gather
       - Verify all writes succeeded and all reads return correct data
       - Verify no deadlocks or connection pool exhaustion (test completes within 10 seconds)

       For the "3 separate processes" success criterion (SC 5), the test can use concurrent async tasks with separate sessions (proving concurrent session access). A true multi-process test using subprocess is acceptable but optional — the critical thing is concurrent database operations without corruption.

    3. Run the tests:
       - Ensure docker-compose postgres is running
       - `uv run pytest tests/test_forecast_persistence.py tests/test_concurrent_db.py -v`
  </action>
  <verify>
    - `uv run pytest tests/test_forecast_persistence.py -v` — all tests pass
    - `uv run pytest tests/test_concurrent_db.py -v` — all tests pass
    - No database errors, no connection pool exhaustion, no deadlocks
  </verify>
  <done>ForecastService persistence round-trip verified: predict output -> persist to PostgreSQL -> retrieve via service and via SQL both return correct data. Three concurrent database writers complete without errors or data corruption.</done>
</task>

</tasks>

<verification>
1. ForecastService imports and has all required methods
2. Persistence round-trip: persist -> retrieve by ID matches
3. Persistence round-trip: persist -> retrieve by country includes the forecast
4. Concurrent database access: 3 async tasks read/write without errors
5. All tests pass via pytest
</verification>

<success_criteria>
- ForecastService.persist_forecast() writes a Prediction row to PostgreSQL
- ForecastService.get_forecast_by_id() retrieves and reconstructs ForecastResponse DTO
- ForecastService.get_forecasts_by_country() returns paginated results
- prediction_to_dto correctly maps ORM -> DTO including nested scenarios
- 3 concurrent database sessions read/write without corruption
- All tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/09-api-foundation/09-05-SUMMARY.md`
</output>
