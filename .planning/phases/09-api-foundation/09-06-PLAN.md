---
phase: 09-api-foundation
plan: 06
type: execute
wave: 3
depends_on: ["09-05"]
files_modified:
  - src/api/services/__init__.py
  - src/api/services/forecast_service.py
  - src/api/routes/v1/forecasts.py
  - tests/test_forecast_persistence.py
  - tests/test_concurrent_db.py
autonomous: true

must_haves:
  truths:
    - "ForecastService wraps EnsemblePredictor.predict() and persists the result to PostgreSQL"
    - "A persisted forecast is retrievable via both direct SQL query and GET /api/v1/forecasts/{id}"
    - "Three separate Python processes can read/write PostgreSQL without errors or data corruption"
    - "ForecastService maps ForecastOutput + EnsemblePrediction to the Prediction ORM model correctly"
    - "GET /api/v1/forecasts/{id} queries PostgreSQL via ForecastService first, falls back to fixture if None"
    - "Smoke-test writes succeed for outcome_records, calibration_weights, and ingest_runs tables"
  artifacts:
    - path: "src/api/services/forecast_service.py"
      provides: "ForecastService that calls predict() and persists to PostgreSQL"
      contains: "class ForecastService"
    - path: "src/api/routes/v1/forecasts.py"
      provides: "Updated GET /forecasts/{id} wired to ForecastService with fixture fallback"
      contains: "ForecastService"
    - path: "tests/test_forecast_persistence.py"
      provides: "Test that predict -> persist -> retrieve round-trips correctly"
      contains: "test_forecast_persist"
    - path: "tests/test_concurrent_db.py"
      provides: "Concurrent database access test with 3 real OS processes"
      contains: "subprocess"
  key_links:
    - from: "src/api/services/forecast_service.py"
      to: "src/forecasting/ensemble_predictor.py"
      via: "Calls EnsemblePredictor.predict() then persists result"
      pattern: "EnsemblePredictor|predict"
    - from: "src/api/services/forecast_service.py"
      to: "src/db/models.py"
      via: "Maps ForecastOutput to Prediction ORM model"
      pattern: "Prediction\\("
    - from: "src/api/services/forecast_service.py"
      to: "src/api/schemas/forecast.py"
      via: "Returns ForecastResponse DTO from persisted data"
      pattern: "ForecastResponse"
    - from: "src/api/routes/v1/forecasts.py"
      to: "src/api/services/forecast_service.py"
      via: "GET /forecasts/{id} queries PostgreSQL via ForecastService"
      pattern: "ForecastService|get_forecast_by_id"
---

<objective>
Wire the EnsemblePredictor to PostgreSQL persistence, update the GET /forecasts/{id} route to query PostgreSQL, and verify concurrent multi-process database access — closing the last success criteria for Phase 9.

Purpose: Success criterion 4 requires that `EnsemblePredictor.predict()` persists forecasts to PostgreSQL and they're retrievable via `GET /api/v1/forecasts/{id}`. This plan creates the ForecastService (the glue between prediction and persistence), wires the route to use it, and verifies that three separate OS processes (not just async tasks) can read/write PostgreSQL concurrently. This concurrent access pattern is what Phases 10 and 13 depend on (FastAPI + ingest daemon + prediction pipeline).

Output: ForecastService class that the daily pipeline (Phase 10) will use. Updated route handler. Passing tests for persistence round-trip, multi-process concurrent database access, and smoke writes for all PostgreSQL tables.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/phases/09-api-foundation/09-CONTEXT.md
@.planning/phases/09-api-foundation/09-RESEARCH.md

# EnsemblePredictor output types:
@src/forecasting/ensemble_predictor.py
@src/forecasting/models.py

# Database layer from Plan 01:
@src/db/models.py
@src/db/postgres.py

# API schemas from Plan 02:
@src/api/schemas/forecast.py

# API routes from Plan 05 (to update GET /forecasts/{id}):
@src/api/routes/v1/forecasts.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: ForecastService — predict, persist, retrieve — and route wiring</name>
  <files>
    src/api/services/__init__.py
    src/api/services/forecast_service.py
    src/api/routes/v1/forecasts.py
  </files>
  <action>
    1. Create src/api/services/__init__.py (empty).

    2. Create src/api/services/forecast_service.py:

       class ForecastService:
           """Bridges EnsemblePredictor with PostgreSQL persistence.

           The predictor is kept pure — it knows nothing about databases.
           ForecastService calls predict(), maps the output to ORM models,
           persists to PostgreSQL, and returns API-ready DTOs.
           """

           def __init__(self, session: AsyncSession):
               self.session = session

           async def persist_forecast(
               self,
               forecast_output: ForecastOutput,
               ensemble_prediction: EnsemblePrediction,
               country_iso: Optional[str] = None,
           ) -> Prediction:
               """Map ForecastOutput + EnsemblePrediction to Prediction ORM model and persist.

               Field mapping (see 09-RESEARCH.md "EnsemblePredictor Integration Point"):
               - question: forecast_output.question
               - prediction: forecast_output.prediction
               - probability: forecast_output.probability (the calibrated ensemble probability)
               - confidence: forecast_output.confidence
               - horizon_days: forecast_output.horizon_days (default 30 if not present)
               - category: ensemble_prediction.category or "general"
               - reasoning_summary: forecast_output.reasoning_summary or first 500 chars of prediction
               - evidence_count: len(evidence sources across all scenarios)
               - scenarios_json: serialize scenarios to list[dict] via ScenarioDTO mapping
               - ensemble_info_json: {llm_probability, tkg_probability, weights, temperature}
               - calibration_json: {category, temperature, historical_accuracy, brier_score, sample_size}
               - entities: extract unique entity names from scenarios
               - country_iso: from parameter
               - created_at: now(UTC)
               - expires_at: now(UTC) + timedelta(days=horizon_days)

               Persist via session.add() + session.flush() to get the ID back.
               Return the Prediction ORM object.
               """

           async def get_forecast_by_id(self, forecast_id: str) -> Optional[ForecastResponse]:
               """Retrieve a forecast from PostgreSQL and return as ForecastResponse DTO.

               Query Prediction table by id.
               Reconstruct ForecastResponse from ORM fields:
               - Deserialize scenarios_json back to list[ScenarioDTO]
               - Deserialize ensemble_info_json back to EnsembleInfoDTO
               - Deserialize calibration_json back to CalibrationDTO
               Return None if not found.
               """

           async def get_forecasts_by_country(
               self, country_iso: str, cursor: Optional[str] = None, limit: int = 20
           ) -> PaginatedResponse[ForecastResponse]:
               """Retrieve forecasts for a country with cursor pagination.

               Query Prediction table filtered by country_iso, ordered by created_at DESC.
               Decode cursor if provided (contains id + timestamp for keyset pagination).
               Apply limit+1 pattern to determine has_more.
               Return PaginatedResponse with next_cursor if more results exist.
               """

           @staticmethod
           def prediction_to_dto(prediction: Prediction) -> ForecastResponse:
               """Convert Prediction ORM model to ForecastResponse DTO.

               This is the single source of truth for ORM->DTO mapping.
               """

       Note on ForecastOutput mapping: The existing ForecastOutput model (src/forecasting/models.py) has fields like question, prediction, probability, confidence, scenario_tree. The scenario_tree.scenarios are Scenario objects (not ScenarioDTO). The mapping must convert Scenario -> ScenarioDTO:
       - Scenario.scenario_id -> ScenarioDTO.scenario_id
       - Scenario.description -> ScenarioDTO.description
       - Scenario.probability -> ScenarioDTO.probability
       - Scenario.answers_affirmative -> ScenarioDTO.answers_affirmative
       - Scenario.entities -> [e.name for e in Scenario.entities] (Entity objects to strings)
       - Scenario.timeline -> [te.description for te in Scenario.timeline] (TimelineEvent to strings)
       - Scenario.reasoning_path -> EvidenceDTO list mapping
       - Scenario.child_ids -> resolve from scenario tree for child_scenarios

       If the mapping is complex, create a private _map_scenario(scenario: Scenario) -> ScenarioDTO helper.

    3. UPDATE src/api/routes/v1/forecasts.py — wire GET /forecasts/{id} to ForecastService:
       - Import ForecastService from src.api.services.forecast_service
       - Modify the GET /forecasts/{forecast_id} handler to:
         a. Create ForecastService(session=db) where db is the injected session
         b. Call service.get_forecast_by_id(forecast_id)
         c. If result is not None, return it (PostgreSQL hit)
         d. If result is None, fall back to fixture lookup (existing behavior)
         e. If fixture lookup also misses, return 404 ProblemDetail
       - This ensures SC-4 is satisfied: persisted forecasts ARE retrievable via the API endpoint.
       - The fixture fallback preserves backward compatibility for Phase 9 mock data.
  </action>
  <verify>
    - `uv run python -c "from src.api.services.forecast_service import ForecastService; print('Import OK')"` succeeds
    - `uv run python -c "
import inspect
from src.api.services.forecast_service import ForecastService
methods = [m for m in dir(ForecastService) if not m.startswith('_')]
print(f'Public methods: {methods}')
assert 'persist_forecast' in methods
assert 'get_forecast_by_id' in methods
assert 'get_forecasts_by_country' in methods
assert 'prediction_to_dto' in methods
print('All methods present')
"` succeeds
    - `grep -n "ForecastService" src/api/routes/v1/forecasts.py` shows the route imports and uses ForecastService
    - `grep -n "get_forecast_by_id" src/api/routes/v1/forecasts.py` shows the route calls get_forecast_by_id
  </verify>
  <done>ForecastService class exists with persist_forecast, get_forecast_by_id, get_forecasts_by_country, and prediction_to_dto methods. GET /forecasts/{id} route queries PostgreSQL via ForecastService first, falls back to fixture if None.</done>
</task>

<task type="auto">
  <name>Task 2: Persistence round-trip test + multi-process concurrent DB test + table smoke writes</name>
  <files>
    tests/test_forecast_persistence.py
    tests/test_concurrent_db.py
  </files>
  <action>
    1. Create tests/test_forecast_persistence.py:
       - Use pytest-asyncio for async tests
       - Test: create a mock ForecastOutput + EnsemblePrediction (use the existing dataclass constructors with minimal valid data), persist via ForecastService, then:
         a. Retrieve by ID via ForecastService.get_forecast_by_id -> verify all fields match
         b. Retrieve by country via ForecastService.get_forecasts_by_country -> verify it appears in list
         c. Verify the Prediction row exists in PostgreSQL via direct SQL query
       - Test: persist_forecast with missing optional fields (no country_iso, no TKG prediction) succeeds
       - Test: prediction_to_dto correctly reconstructs nested ScenarioDTO from scenarios_json

       IMPORTANT: These tests require a running PostgreSQL. Use the docker-compose postgres service. The test should:
       a. Create a test-specific database or use a transaction that rolls back
       b. Recommended: use a fixture that creates an async session with a savepoint, rolls back after each test

       If creating these tests is too complex due to the EnsemblePredictor's dependencies (it needs Gemini, TKG model, etc.), create mock/synthetic ForecastOutput and EnsemblePrediction objects directly using the dataclass constructors with hardcoded data. DO NOT call the real EnsemblePredictor.predict().

    2. Create tests/test_concurrent_db.py:
       MANDATORY: Use real OS processes via subprocess.Popen, NOT just async tasks.

       The test must prove that 3 separate Python processes can concurrently read/write PostgreSQL. This is SC-5: "Three separate Python processes can read/write PostgreSQL concurrently."

       Implementation approach:
       a. Create a helper script (or use inline Python via subprocess) that each subprocess runs:
          - Process 1 (simulates FastAPI): writes a Prediction row, reads it back, prints result as JSON
          - Process 2 (simulates ingest daemon): writes an IngestRun row, reads it back, prints result as JSON
          - Process 3 (simulates prediction pipeline): writes a Prediction row, reads it back, prints result as JSON
       b. The test function spawns all 3 processes via subprocess.Popen simultaneously
       c. Waits for all to complete (with timeout of 30 seconds)
       d. Parses stdout from each process to verify success
       e. Asserts all 3 completed with returncode 0
       f. Asserts no data corruption (each process's read returns the data it wrote)

       Each subprocess must create its own async engine and session — they do NOT share a connection pool. This is the whole point: proving inter-process PostgreSQL access works.

       DO NOT mark the subprocess-based test as optional or xfail. It is the primary mechanism for proving SC-5.

    3. Add smoke-test writes for INFRA-02/03/04 tables in the concurrent DB test:
       In addition to Prediction and IngestRun writes, the concurrent test (or a separate test in the same file) must also:
       a. Write one OutcomeRecord row to outcome_records table, read it back
       b. Write one CalibrationWeight row to calibration_weights table, read it back
       c. Write one additional IngestRun row (if not already covered), read it back
       These can be done in one of the 3 subprocesses or in a separate test function. The point is to prove the write path works for ALL PostgreSQL tables, not just predictions.

    4. Run the tests:
       - Ensure docker-compose postgres is running
       - `uv run pytest tests/test_forecast_persistence.py tests/test_concurrent_db.py -v`
  </action>
  <verify>
    - `uv run pytest tests/test_forecast_persistence.py -v` — all tests pass
    - `uv run pytest tests/test_concurrent_db.py -v` — all tests pass, including the subprocess-based multi-process test
    - The subprocess test log output shows 3 separate PIDs writing/reading successfully
    - No database errors, no connection pool exhaustion, no deadlocks
  </verify>
  <done>ForecastService persistence round-trip verified: predict output -> persist to PostgreSQL -> retrieve via service and via SQL and via GET /forecasts/{id} all return correct data. Three separate OS processes concurrently write/read PostgreSQL without errors or data corruption. Smoke-test writes for outcome_records, calibration_weights, and ingest_runs tables all succeed.</done>
</task>

</tasks>

<verification>
1. ForecastService imports and has all required methods
2. GET /forecasts/{id} route queries PostgreSQL via ForecastService, falls back to fixture
3. Persistence round-trip: persist -> retrieve by ID matches
4. Persistence round-trip: persist -> retrieve by country includes the forecast
5. Multi-process concurrent database access: 3 OS subprocesses read/write without errors
6. Smoke writes for outcome_records, calibration_weights, ingest_runs all succeed
7. All tests pass via pytest
</verification>

<success_criteria>
- ForecastService.persist_forecast() writes a Prediction row to PostgreSQL
- ForecastService.get_forecast_by_id() retrieves and reconstructs ForecastResponse DTO
- ForecastService.get_forecasts_by_country() returns paginated results
- GET /api/v1/forecasts/{id} queries PostgreSQL first, fixture fallback second
- prediction_to_dto correctly maps ORM -> DTO including nested scenarios
- 3 separate OS processes (subprocess.Popen) read/write PostgreSQL concurrently without corruption
- Write path works for ALL 5 PostgreSQL tables (predictions, outcome_records, calibration_weights, ingest_runs, api_keys)
- All tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/09-api-foundation/09-06-SUMMARY.md`
</output>
