---
phase: 08-graph-partitioning
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/knowledge_graph/partition_index.py
  - src/knowledge_graph/partition_manager.py
  - tests/test_partition_index.py
  - tests/test_partition_manager.py
autonomous: true

must_haves:
  truths:
    - "Partition index stores entity-to-partition mappings in SQLite"
    - "Partition manager creates temporal partitions from a graph"
    - "Partition manager saves partitions to disk as GraphML files"
    - "Partition manager loads partitions on-demand with LRU eviction"
    - "Entity index survives process restart"
  artifacts:
    - path: "src/knowledge_graph/partition_index.py"
      provides: "EntityPartitionIndex class with SQLite persistence"
      exports: ["EntityPartitionIndex"]
      contains: "CREATE TABLE.*entity_partitions"
    - path: "src/knowledge_graph/partition_manager.py"
      provides: "PartitionManager class with temporal partitioning"
      exports: ["PartitionManager"]
      contains: "def partition_by_time_windows"
    - path: "tests/test_partition_index.py"
      provides: "Tests for partition index"
      min_lines: 50
    - path: "tests/test_partition_manager.py"
      provides: "Tests for partition manager"
      min_lines: 80
  key_links:
    - from: "src/knowledge_graph/partition_manager.py"
      to: "src/knowledge_graph/partition_index.py"
      via: "import EntityPartitionIndex"
      pattern: "from.*partition_index.*import.*EntityPartitionIndex"
    - from: "src/knowledge_graph/partition_manager.py"
      to: "networkx"
      via: "GraphML read/write"
      pattern: "nx\\.(read|write)_graphml"
---

<objective>
Implement partition infrastructure: SQLite-backed partition index and partition manager with temporal-first partitioning strategy.

Purpose: This plan creates the foundational components for graph partitioning. The partition index provides O(1) entity-to-partition lookups persisted in SQLite. The partition manager handles creating, saving, and loading partitions with an LRU cache to prevent memory exhaustion.

Output: Two new modules (`partition_index.py`, `partition_manager.py`) with full test coverage, ready for the cross-partition query routing layer.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/08-graph-partitioning/08-RESEARCH.md

# Existing code to integrate with
@src/knowledge_graph/persistence.py
@src/knowledge_graph/graph_traversal.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement SQLite partition index</name>
  <files>src/knowledge_graph/partition_index.py, tests/test_partition_index.py</files>
  <action>
Create `src/knowledge_graph/partition_index.py` with `EntityPartitionIndex` class:

1. **Schema** (from RESEARCH.md Pattern: SQLite partition index):
   - `entity_partitions` table: entity_id TEXT, partition_id TEXT, is_home INTEGER, edge_count INTEGER, PRIMARY KEY (entity_id, partition_id)
   - `partition_meta` table: partition_id TEXT PRIMARY KEY, time_window_start TEXT, time_window_end TEXT, node_count INTEGER, edge_count INTEGER, file_path TEXT, created_at TEXT
   - Indexes on entity_id and partition_id columns

2. **Methods**:
   - `__init__(self, db_path: Path)` - Create connection, initialize schema
   - `register_partition(partition_id, entities, time_window, stats, file_path)` - Insert partition metadata and entity mappings
   - `get_entity_partitions(entity_id) -> List[str]` - Return partitions containing entity, ordered by is_home DESC, edge_count DESC
   - `get_partitions_in_time_range(time_start, time_end) -> List[str]` - Return partitions overlapping time range
   - `get_partition_meta(partition_id) -> Optional[Dict]` - Return partition metadata
   - `update_entity_edge_count(entity_id, partition_id, edge_count)` - Update edge count for entity in partition
   - `mark_home_partition(entity_id, partition_id)` - Set is_home=1 for entity in partition, is_home=0 elsewhere
   - `close()` - Close database connection

3. **Constraints**:
   - Use `executemany` for bulk inserts (performance)
   - Use `INSERT OR REPLACE` for idempotent operations
   - Transaction commit after register_partition completes

4. **Tests** in `tests/test_partition_index.py`:
   - test_schema_creation: Fresh db has correct tables
   - test_register_partition: Metadata and entities stored correctly
   - test_get_entity_partitions: Returns partitions in correct order
   - test_get_partitions_in_time_range: Time range filtering works
   - test_entity_appears_in_multiple_partitions: Multi-partition entities handled
   - test_persistence_across_restart: Close and reopen db, data survives
  </action>
  <verify>
```bash
cd /home/kondraki/personal/geopol && python -m pytest tests/test_partition_index.py -v
```
All tests pass.
  </verify>
  <done>
EntityPartitionIndex class exists with SQLite persistence, all CRUD operations work, tests verify persistence across restarts.
  </done>
</task>

<task type="auto">
  <name>Task 2: Implement partition manager with temporal partitioning</name>
  <files>src/knowledge_graph/partition_manager.py, tests/test_partition_manager.py</files>
  <action>
Create `src/knowledge_graph/partition_manager.py` with `PartitionManager` class:

1. **Constructor**:
   - `__init__(self, partition_dir: Path, index: EntityPartitionIndex, max_cached_partitions: int = 4, max_memory_mb: int = 8192)`
   - `partition_dir`: Directory for partition storage (created if not exists)
   - LRU cache for loaded partitions (OrderedDict tracking access order)

2. **Core methods**:
   - `partition_graph(graph: nx.MultiDiGraph, window_days: int = 30) -> List[str]`:
     - Partition by time windows using edge timestamps (see RESEARCH.md Pattern 1)
     - Create partition directories: `{partition_dir}/{partition_id}/`
     - Save each partition as `graph.graphml` using `nx.write_graphml`
     - Register in EntityPartitionIndex with entity mappings and metadata
     - Return list of partition_ids created
   - `load_partition(partition_id: str) -> nx.MultiDiGraph`:
     - Check LRU cache first, return if present
     - Evict oldest if at max_cached_partitions
     - Load from `{partition_dir}/{partition_id}/graph.graphml`
     - Add to cache, update access order
     - Return graph
   - `get_partition_path(partition_id: str) -> Path`: Return GraphML file path
   - `list_partitions() -> List[str]`: Return all partition IDs from index

3. **LRU eviction** (from RESEARCH.md Memory-Aware Partition Loading):
   - Track access order in list
   - On load: move to end if cached, evict oldest if at capacity
   - Explicit `gc.collect()` after eviction (Python memory fragmentation pitfall)

4. **Time window partitioning logic**:
   - Parse edge timestamps, bucket by `window_days`
   - Window ID format: `YYYY-MM-DD` of window start
   - Handle edges without timestamps: assign to "no-timestamp" partition
   - Copy node attributes when adding to partition subgraph

5. **Constraints**:
   - Do NOT use METIS in this plan (deferred to future if needed for large partitions)
   - Partition IDs are time-window strings for temporal partitioning
   - Each partition is independent GraphML file

6. **Tests** in `tests/test_partition_manager.py`:
   - test_partition_by_time_windows: Graph with edges across 3 months creates 3+ partitions
   - test_partition_saves_graphml: Each partition directory contains graph.graphml
   - test_partition_entities_indexed: All entities appear in partition index
   - test_load_partition_caching: Second load returns cached copy (no file I/O)
   - test_lru_eviction: Loading 5 partitions with max_cached=4 evicts oldest
   - test_partition_roundtrip: Loaded partition has same nodes/edges as original subgraph
   - test_empty_graph: Empty graph produces no partitions
   - test_no_timestamp_edges: Edges without timestamps go to fallback partition
  </action>
  <verify>
```bash
cd /home/kondraki/personal/geopol && python -m pytest tests/test_partition_manager.py -v
```
All tests pass.

**LRU eviction state verification (SCALE-01 critical):**
```bash
cd /home/kondraki/personal/geopol && python -c "
import tempfile
from pathlib import Path
import networkx as nx
from datetime import datetime, timedelta
from src.knowledge_graph.partition_index import EntityPartitionIndex
from src.knowledge_graph.partition_manager import PartitionManager

# Create graph spanning 5 months to produce 5 partitions
g = nx.MultiDiGraph()
base = datetime(2024, 1, 1)
for month in range(5):
    ts = base + timedelta(days=month * 30)
    g.add_edge(f'A{month}', f'B{month}', timestamp=ts.isoformat())

with tempfile.TemporaryDirectory() as tmpdir:
    db = Path(tmpdir) / 'idx.db'
    pdir = Path(tmpdir) / 'parts'
    idx = EntityPartitionIndex(db)
    mgr = PartitionManager(pdir, idx, max_cached_partitions=4)

    pids = mgr.partition_graph(g, window_days=30)
    assert len(pids) >= 5, f'Expected 5+ partitions, got {len(pids)}'

    # Load all 5 partitions - should evict oldest
    for pid in pids:
        mgr.load_partition(pid)

    # Verify cache size respects limit
    cache_size = len(mgr._cache)
    assert cache_size == 4, f'FAIL: cache has {cache_size} partitions, expected 4 (max_cached_partitions)'

    # Verify oldest partition was evicted (first loaded should be gone)
    assert pids[0] not in mgr._cache, f'FAIL: oldest partition {pids[0]} still in cache'

    idx.close()
    print(f'SUCCESS: LRU eviction working - cache size={cache_size}, oldest evicted')
"
```
  </verify>
  <done>
PartitionManager creates temporal partitions, saves to GraphML, loads with LRU caching. Cache respects max_cached_partitions limit and evicts oldest partition when capacity exceeded.
  </done>
</task>

</tasks>

<verification>
After both tasks complete:

1. Run full test suite for new modules:
```bash
cd /home/kondraki/personal/geopol && python -m pytest tests/test_partition_index.py tests/test_partition_manager.py -v --tb=short
```

2. Integration smoke test:
```python
# Quick validation script
from pathlib import Path
import tempfile
import networkx as nx
from src.knowledge_graph.partition_index import EntityPartitionIndex
from src.knowledge_graph.partition_manager import PartitionManager

# Create test graph with temporal edges
g = nx.MultiDiGraph()
g.add_edge("USA", "CHN", timestamp="2024-01-15", relation="trade")
g.add_edge("USA", "RUS", timestamp="2024-02-20", relation="sanction")
g.add_edge("CHN", "RUS", timestamp="2024-03-10", relation="cooperate")

with tempfile.TemporaryDirectory() as tmpdir:
    db_path = Path(tmpdir) / "index.db"
    partition_dir = Path(tmpdir) / "partitions"

    index = EntityPartitionIndex(db_path)
    manager = PartitionManager(partition_dir, index, max_cached_partitions=2)

    # Partition the graph
    partition_ids = manager.partition_graph(g, window_days=30)
    print(f"Created {len(partition_ids)} partitions: {partition_ids}")

    # Verify entity lookup
    usa_partitions = index.get_entity_partitions("USA")
    print(f"USA appears in partitions: {usa_partitions}")

    # Load partition
    p = manager.load_partition(partition_ids[0])
    print(f"Partition {partition_ids[0]} has {p.number_of_nodes()} nodes, {p.number_of_edges()} edges")

    index.close()
    print("SUCCESS")
```
</verification>

<success_criteria>
- [ ] EntityPartitionIndex persists entity-partition mappings in SQLite
- [ ] EntityPartitionIndex survives process restart
- [ ] PartitionManager partitions graph by time windows
- [ ] PartitionManager saves partitions as GraphML files
- [ ] PartitionManager loads partitions with LRU caching
- [ ] LRU cache respects max_cached_partitions (verified: len(manager._cache) == 4 after loading 5)
- [ ] All tests pass
- [ ] Integration smoke test prints SUCCESS
</success_criteria>

<output>
After completion, create `.planning/phases/08-graph-partitioning/08-01-SUMMARY.md`
</output>
