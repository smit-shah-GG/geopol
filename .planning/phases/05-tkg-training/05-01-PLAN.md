---
phase: 05-tkg-training
plan: 01
type: execute
---

<objective>
Collect and prepare historical GDELT event data for TKG training.

Purpose: Build a 30-day historical dataset from GDELT to train the temporal knowledge graph predictor.
Output: Stored GDELT events in data/gdelt/ with entities extracted and temporal structure ready for TKG construction.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-phase.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-tkg-training/05-CONTEXT.md
@.planning/phases/05-tkg-training/05-RESEARCH.md
@src/gdelt_client.py
@src/data/event_store.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create GDELT historical data collector</name>
  <files>src/training/data_collector.py</files>
  <action>
  Create data collector that uses gdeltPyR to fetch 30 days of historical GDELT events. Use the existing GDELTClient as reference but extend for bulk historical collection. Implement:
  - collect_historical_data(start_date, end_date): Fetch events in daily chunks
  - Include all QuadClass types (1-4) as specified in CONTEXT.md
  - Save raw data to data/gdelt/raw/ with date-based filenames
  - Handle rate limiting with exponential backoff
  - Log progress for each day collected

  Use gdelt.gdelt(version=2) for the Doc API. Process in daily chunks to avoid memory issues. Focus on events table, not GKG for now.
  </action>
  <verify>python -c "from src.training.data_collector import GDELTHistoricalCollector; print('Import successful')"</verify>
  <done>Data collector module created with historical collection methods</done>
</task>

<task type="auto">
  <name>Task 2: Collect 30 days of GDELT data</name>
  <files>scripts/collect_training_data.py, data/gdelt/raw/</files>
  <action>
  Create script to collect last 30 days of GDELT events using the collector. Implement:
  - Calculate date range (30 days back from today)
  - Use GDELTHistoricalCollector to fetch data day by day
  - Save each day as CSV: data/gdelt/raw/gdelt_YYYY-MM-DD.csv
  - Track collection progress with tqdm or simple prints
  - Handle any API errors gracefully (skip day if needed)
  - Log total events collected and file sizes

  Run the script to actually collect the data. This may take 5-10 minutes due to API rate limits.
  </action>
  <verify>ls data/gdelt/raw/*.csv | wc -l # Should show ~30 files</verify>
  <done>30 days of GDELT event data collected and saved</done>
</task>

<task type="auto">
  <name>Task 3: Process and prepare events for TKG</name>
  <files>src/training/data_processor.py, data/gdelt/processed/events.parquet</files>
  <action>
  Create data processor to convert raw GDELT events into TKG-ready format. Implement:
  - load_raw_events(): Read all CSV files from data/gdelt/raw/
  - extract_entities(): Get Actor1Name, Actor2Name as entities
  - extract_relations(): Use EventCode/QuadClass as relation types
  - build_temporal_events(): Create (entity1, relation, entity2, timestamp) tuples
  - save_processed(): Save as Parquet for efficient loading

  Process should handle missing values, normalize entity names (uppercase, strip whitespace), and convert dates to datetime objects. Filter out events with missing actors.
  </action>
  <verify>python -c "import pandas as pd; df = pd.read_parquet('data/gdelt/processed/events.parquet'); print(f'Processed {len(df)} events with columns: {df.columns.tolist()}')"</verify>
  <done>GDELT events processed and saved in TKG-ready format</done>
</task>

</tasks>

<verification>
Before declaring phase complete:
- [ ] Data collector imports successfully
- [ ] ~30 CSV files exist in data/gdelt/raw/
- [ ] Processed events.parquet exists and is readable
- [ ] Events have entity1, relation, entity2, timestamp columns
</verification>

<success_criteria>
- All tasks completed
- 30 days of GDELT data collected
- Data processed into TKG format
- No import errors
</success_criteria>

<output>
After completion, create `.planning/phases/05-tkg-training/05-01-SUMMARY.md`:

# Phase 5 Plan 1: GDELT Data Collection Summary

**Collected 30 days of historical GDELT events for TKG training**

## Accomplishments

- GDELTHistoricalCollector implemented with bulk collection
- 30 days of event data collected via gdeltPyR
- Events processed into TKG-ready format

## Files Created/Modified

- `src/training/data_collector.py` - Historical data collection
- `scripts/collect_training_data.py` - Collection script
- `data/gdelt/raw/*.csv` - Raw event files
- `data/gdelt/processed/events.parquet` - Processed events

## Next Step

Ready for 05-02-PLAN.md (RE-GCN implementation)
</output>