---
phase: 03-hybrid-forecasting
plan: 01
type: execute
---

<objective>
Set up Gemini API integration with multi-step reasoning pipeline for scenario generation.

Purpose: Establish the LLM-first forecasting approach where Gemini generates scenarios that get validated and refined.
Output: Working Gemini client with scenario generation, rate limiting, and structured output parsing.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
./summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-hybrid-forecasting/03-RESEARCH.md
@.planning/phases/03-hybrid-forecasting/03-CONTEXT.md
@.planning/phases/02-knowledge-graph-engine/02-01-SUMMARY.md
@.planning/phases/02-knowledge-graph-engine/02-03-SUMMARY.md
@src/knowledge_graph/temporal_graph_builder.py
@src/knowledge_graph/query_engine.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Set up Google GenAI SDK with configuration</name>
  <files>src/forecasting/gemini_client.py, requirements.txt</files>
  <action>Create GeminiClient class using google-genai SDK (not google-generativeai - deprecated). Configure with API key from environment, set model to "models/gemini-2.0-flash-exp" for development. Implement exponential backoff retry logic using tenacity library (stop_after_attempt=3, wait_exponential(multiplier=1, min=4, max=60)). Add rate limit tracking with sliding window (5 RPM for free tier). Include automatic context caching support from SDK. Add google-genai>=1.0, tenacity>=8.0, pydantic>=2.0 to requirements.txt.</action>
  <verify>python -c "from src.forecasting.gemini_client import GeminiClient; client = GeminiClient(); print('Client initialized')" returns no errors</verify>
  <done>GeminiClient class exists with rate limiting, retry logic, and proper SDK initialization</done>
</task>

<task type="auto">
  <name>Task 2: Implement scenario generation with structured output</name>
  <files>src/forecasting/scenario_generator.py, src/forecasting/models.py</files>
  <action>Create Pydantic models for ScenarioTree structure with fields: scenario_id, description, entities, timeline, probability, reasoning_path. Implement ScenarioGenerator class with generate_scenarios() method that creates prompts for Gemini including context about the geopolitical question, relevant entities, and temporal constraints. Use response_schema parameter in generate_content() for structured JSON output. Implement multi-step generation: initial scenarios -> validation placeholders -> refined scenarios. Use response_mime_type="application/json" for reliable parsing.</action>
  <verify>python -c "from src.forecasting.scenario_generator import ScenarioGenerator; gen = ScenarioGenerator(); print('Generator ready')" returns no errors</verify>
  <done>ScenarioGenerator produces structured ScenarioTree objects from Gemini responses</done>
</task>

<task type="auto">
  <name>Task 3: Create multi-step reasoning orchestrator</name>
  <files>src/forecasting/reasoning_orchestrator.py, tests/test_reasoning_orchestrator.py</files>
  <action>Implement ReasoningOrchestrator that coordinates the multi-step flow: (1) generate initial scenarios from question, (2) prepare validation feedback structure (placeholder for graph validation - will be integrated in next plan), (3) refine scenarios based on feedback, (4) extract final predictions with confidence scores. Use LangChain's SequentialChain for step management. Each step should preserve reasoning chains for explainability. Add comprehensive error handling for API failures. Create test with mock Gemini responses to verify the flow works end-to-end.</action>
  <verify>python -m pytest tests/test_reasoning_orchestrator.py -v passes all tests</verify>
  <done>ReasoningOrchestrator executes full multi-step reasoning pipeline with proper state management</done>
</task>

</tasks>

<verification>
Before declaring phase complete:
- [ ] GeminiClient handles rate limits gracefully
- [ ] Scenario generation produces valid structured output
- [ ] Multi-step reasoning preserves context between steps
- [ ] All tests pass with mock API responses
- [ ] No hardcoded API keys in code
</verification>

<success_criteria>

- All tasks completed
- All verification checks pass
- No errors or warnings introduced
- Gemini integration works with proper rate limiting
- Structured scenario generation functioning
- Multi-step reasoning pipeline operational
</success_criteria>

<output>
After completion, create `.planning/phases/03-hybrid-forecasting/03-01-SUMMARY.md`:

# Phase 3 Plan 1: Gemini API Integration Summary

**Established LLM-first forecasting pipeline with Gemini API for structured scenario generation**

## Accomplishments

- Integrated Google GenAI SDK with rate limiting and retry logic
- Created structured scenario models with Pydantic
- Implemented multi-step reasoning orchestrator
- Set up comprehensive test framework with mocks

## Files Created/Modified

- `src/forecasting/gemini_client.py` - Gemini API client with rate limiting
- `src/forecasting/scenario_generator.py` - Scenario generation from prompts
- `src/forecasting/models.py` - Pydantic models for scenarios
- `src/forecasting/reasoning_orchestrator.py` - Multi-step reasoning flow
- `tests/test_reasoning_orchestrator.py` - Test coverage
- `requirements.txt` - Added google-genai, tenacity, pydantic

## Decisions Made

- Used google-genai SDK (new unified SDK) instead of deprecated google-generativeai
- Chose gemini-2.0-flash-exp for development (faster, cheaper)
- Implemented 5 RPM rate limiting for free tier compatibility

## Issues Encountered

[Problems and resolutions, or "None"]

## Next Step

Ready for 03-02-PLAN.md (RAG pipeline for historical grounding)
</output>